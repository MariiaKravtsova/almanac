---
layout: post
title:  "Toes in Machine Learning"
date:   2016-12-18 17:07:00
categories: learning
comments: yes
---

Machine Learning seems like a very complex subject, it has a lot of prerequisites, and it is
intimidating to just open a book and start reading. The books that I looked at had big words
and too much math, the one I did not know at the time. This semester I was taking linear algebra,
which solved the math problem, next was the big words problem.

It all started one day with me purchasing a book on sale, it was only $2.99. Make Your Own Neural Network by
Tariq Rashid. I know, I know it's not Machine Learning but hold on. The book walked through an example of building
a neural network that recognizes pictures of hand written numbers. It wasn't the most efficient or the most accurate
neural network, but it was the most simple, and noob friendly. All the foreign words like perceptrons and backpropagation
became familiar.

One week after I learned matrix multiplication in my linear algebra class, I was applying it to my neural net. It was
a fantastic experience. Things clicked, and after finishing the book I wanted to continue this excitement. A friend
of mine recommended Intro to Machine Learning on Udacity. The course was a blast!

It doesn't go into a lot of detail, but it gave me an introduction to different classifiers, and made me code them using sklearn.
Gave me an overview of how to process, train and test the datasets. One downfall was that the course has the same project for
the majority of lessons, it in the Enron dataset, the idea is that you are searching for the people of interest in the Enron
fraud. Although, this was interesting for the first few chapters, it sort of dragged on. Personally, I wasn't as passionate about it as
Katie (the instructor). So instead I did some examples that sklearn provided, on their datasets. Sklearn has some
cool data sets you can import.

Out of the entire course two major chapters were the most interesting to me - Bag of Words and Eigenfaces
example from Principle Component Analysis chapter. Bag of Words gives an overview on how ML deals with languages.
Where is the Eigenfaces recognized pictures of famous people by running numerous principal components on them and feeding into an SVM.
I found that I learn better when I type the example up, but you can go checkout the sklearn page if you are interested.

So what is next? Well, I am taking a Machine Learning course at my university next semester, so that will
keep me busy and excited for a while. However, I do have some projects in mind that I would like to work on.
